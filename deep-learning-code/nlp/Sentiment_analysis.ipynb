{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuNpwVYXo_BK"
      },
      "source": [
        "# Deep learning for sentiment analysis\n",
        "**Task**\n",
        "- Preprocessing data\n",
        "- Load pretrained embedding\n",
        "- Build model\n",
        "- Optimize model with lr_scheduler, early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2UDTDU1bSog"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ9joez_ea-L"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYM5xcmvbVdl",
        "outputId": "ae97441a-a617-45ff-d443-086569c60e07"
      },
      "source": [
        "!gdown --id 1WcbL14nk0kJ1L89Dyy8qW9rl6KM3g5lw\n",
        "!gdown --id 1qOS5qiFOiDYiLUSWXk77jLqvbfLt5Mqn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WcbL14nk0kJ1L89Dyy8qW9rl6KM3g5lw\n",
            "To: /content/test.tsv\n",
            "100% 3.37M/3.37M [00:00<00:00, 109MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qOS5qiFOiDYiLUSWXk77jLqvbfLt5Mqn\n",
            "To: /content/train.tsv\n",
            "100% 8.48M/8.48M [00:00<00:00, 32.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-g93LVreeEC"
      },
      "source": [
        "## Word Embedding [Source](https://fasttext.cc/docs/en/english-vectors.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq3xCaG6cSCA",
        "outputId": "06c08fb8-c248-4fb9-a7fc-7492836be9be"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "!unzip crawl-300d-2M.vec.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-03 13:54:43--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M.vec.zip’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G  28.8MB/s    in 52s     \n",
            "\n",
            "2021-11-03 13:55:35 (28.2 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
            "\n",
            "Archive:  crawl-300d-2M.vec.zip\n",
            "  inflating: crawl-300d-2M.vec       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spkP8M69el5n"
      },
      "source": [
        "# Import requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "11qdKe5JbM6L"
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import numpy as np  \n",
        "import pandas as pd \n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFnC5BI1hizp"
      },
      "source": [
        "# To get reproducible results\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX5rO8Rqqx1h"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFvtNCRjbM6R",
        "outputId": "1f11b437-cc21-42b3-bd63-336b0981f39b"
      },
      "source": [
        "test_file = 'test.tsv'\n",
        "test = pd.read_csv(test_file, delimiter='\\t').fillna('')\n",
        "x_test = test.values[:, 2]\n",
        "\n",
        "train_file = 'train.tsv'\n",
        "train = pd.read_csv(train_file, delimiter='\\t').fillna('')\n",
        "x_train = train.values[:, 2]\n",
        "y_train = train.values[:, 3]\n",
        "\n",
        "print('x_test count: {}'.format(len(x_test)))\n",
        "print('x_train count: {}'.format(len(x_train)))\n",
        "print('y_train count: {}'.format(len(y_train)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test count: 66292\n",
            "x_train count: 156060\n",
            "y_train count: 156060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxemuOVobM6S",
        "outputId": "c3039da8-3bca-4125-c156-f239d3213d06"
      },
      "source": [
        "max_length = 60\n",
        "max_features = 20000\n",
        "\n",
        "x_all = []\n",
        "x_all.extend(x_test)\n",
        "x_all.extend(x_train)\n",
        "\n",
        "np_x_train = None  # ndarray, token sequences\n",
        "np_x_test = None # ndarray, token sequences\n",
        "np_y_train = None # # ndarray, label index\n",
        "\n",
        "tk = Tokenizer(num_words=max_features, lower=True, filters='\\n\\t')\n",
        "# PREPROCESS DATA\n",
        "# START CODE HERE\n",
        "\n",
        "tk.fit_on_texts(x_all)\n",
        "x_train_seq = tk.texts_to_sequences(x_train)\n",
        "x_test_seq = tk.texts_to_sequences(x_test)\n",
        "\n",
        "np_x_train = pad_sequences(x_train_seq, maxlen=max_length,  padding='post')\n",
        "np_x_test = pad_sequences(x_test_seq, maxlen=max_length,  padding='post')\n",
        "np_y_train = to_categorical(y_train)\n",
        "\n",
        "# END CODE HERE\n",
        "\n",
        "    #                                                           #\n",
        "    #  viết các câu lệnh để in ra EXPECTED OUTPUT như bên dưới  #\n",
        "    #                                                           # \n",
        "print ('np_x_train shape: {}'.format(np_x_train.shape))\n",
        "print ('np_x_test shape: {}'.format(np_x_test.shape))\n",
        "print ('np_y_train shape: {}'.format(np_y_train.shape))\n",
        "## EXPECTED OUTPUT:\n",
        "# np_x_train shape: (156060, 60)\n",
        "# np_x_test shape: (66292, 60)\n",
        "# np_y_train shape: (156060, 5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np_x_train shape: (156060, 60)\n",
            "np_x_test shape: (66292, 60)\n",
            "np_y_train shape: (156060, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78DEgOdWgRqa"
      },
      "source": [
        "# Load pretrained embedding metrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeiACfmEbM6T",
        "outputId": "90fcd409-7325-40ee-f479-2892a457bb04"
      },
      "source": [
        "word_dict = tk.word_index\n",
        "embedding_dim = 300\n",
        "embeddings_index = {}\n",
        "\n",
        "with open('crawl-300d-2M.vec', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "max_features = min(max_features, len(word_dict) + 1)\n",
        "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
        "\n",
        "## LOAD EMBEDDING METRIX TO embedding_matrix\n",
        "# START CODE HERE\n",
        "\n",
        "for i in tqdm.tqdm(range(len(lines))):\n",
        "    values = lines[i].rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
        "\n",
        "for word, i in word_dict.items():\n",
        "    if i >= max_features:\n",
        "        break\n",
        "\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# END CODE HERE\n",
        "print('Embedding matrix: {}'.format(embedding_matrix.shape))\n",
        "## EXPECTED OUTPUT:\n",
        "# Embedding matrix: (19479, 300)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1999996/1999996 [02:27<00:00, 13525.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix: (19479, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byEqPMEnq3Rh"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SYrUd_pbM6U",
        "outputId": "93ae2c11-d390-40a2-ba21-128bf356bec3"
      },
      "source": [
        "def one_input_classifier(index, input_length, max_features, class_num, embedding_dim, embedding_matrix):\n",
        "    inputs = Input(shape=(input_length,), name='input_1')\n",
        "    embeddings = Embedding(max_features, embedding_dim,\n",
        "                           weights=[embedding_matrix], input_length=input_length,\n",
        "                           trainable=False, name='embedding_1')(inputs)\n",
        "\n",
        "    ## DEFINE YOUR MODEL (Functional API)\n",
        "    # START CODE HERE\n",
        "    x = SpatialDropout1D(0.3, name='spatial_dropout1d_1')(embeddings)\n",
        "\n",
        "    x = Bidirectional(CuDNNLSTM(128, name='lstm_1', return_sequences=True), name='bidirectional_1')(x)\n",
        "    #                                                                                              #\n",
        "    #  các bạn viết tiếp đoạn này, tham khảo https://www.kaggle.com/antmarakis/bi-lstm-conv-layer  #\n",
        "    #                                                                                              # \n",
        "    ## END CODE HERE\n",
        "    x = Dropout(0.25, name='dropout_1')(x)\n",
        "    x = Conv1D(128, 5, activation='relu', name='conv1d_1')(x)\n",
        "    x = Conv1D(128, 3, activation='relu', name='conv1d_2')(x)\n",
        "    x = Conv1D(128, 1, activation='relu', name='conv1d_3')(x)\n",
        "    x = Dropout(0.25, name='dropout_2')(x)\n",
        "\n",
        "    x = GlobalMaxPooling1D(name='global_maxpool1d_1')(x)\n",
        "    x = Dense(32, activation='relu', name='dense_1')(x)\n",
        "    x = Dropout(0.25, name='dropout_5')(x)\n",
        "\n",
        "    preds = Dense(class_num, activation='softmax', name='preds')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=preds, name='model_{}'.format(index))\n",
        "    model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "class_num = np_y_train.shape[1]\n",
        "epochs = 32\n",
        "batch_size = 1024\n",
        "validation_split = 0.2\n",
        "classifier_num = 1\n",
        "\n",
        "print('Classes: {}'.format(class_num))\n",
        "print('Epochs: {}'.format(epochs))\n",
        "print('Batch size: {}'.format(batch_size))\n",
        "print('Validation split: {:.1}'.format(validation_split))\n",
        "print('Classifiers: {}'.format(classifier_num))\n",
        "\n",
        "# EXPECTED OUTPUT: \n",
        "# Classes: 5\n",
        "# Epochs: 32\n",
        "# Batch size: 1024\n",
        "# Validation split: 0.2\n",
        "# Classifiers: 10"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: 5\n",
            "Epochs: 32\n",
            "Batch size: 1024\n",
            "Validation split: 0.2\n",
            "Classifiers: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kminTpZqnuSb"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ORVCqdbM6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33da90fb-c1ab-49ac-bf08-e07d1f87e1d1"
      },
      "source": [
        "classifiers = []\n",
        "model_index = list(range(classifier_num))  # for ensemble only, kfold split - do it yourself\n",
        "\n",
        "for i in model_index:\n",
        "    classifier = one_input_classifier(i, max_length, max_features, class_num, embedding_dim, embedding_matrix)\n",
        "\n",
        "    if i == 0:\n",
        "        classifier.summary()\n",
        "\n",
        "    hist = classifier.fit(np_x_train, np_y_train, validation_split=validation_split, shuffle=True,\n",
        "                          callbacks=[], epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "    classifier.trainable = False\n",
        "    classifiers.append(classifier)\n",
        "\n",
        "    print('min loss ({}): {:.4}'.format(i, min(hist.history['loss'])))\n",
        "    print('min val_loss ({}): {:.4}'.format(i, min(hist.history['val_loss'])))\n",
        "    print('max accuracy ({}): {:.4}'.format(i, max(hist.history['accuracy'])))\n",
        "    print('max val_accuracy ({}): {:.4}'.format(i, max(hist.history['val_accuracy'])))\n",
        "\n",
        "# EXPECTED VALID ACC FOR SINGLE MODEL >= 0.64"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_0\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 60)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 60, 300)           5843700   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 60, 256)           440320    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 56, 128)           163968    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 54, 128)           49280     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 54, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 54, 128)           0         \n",
            "_________________________________________________________________\n",
            "global_maxpool1d_1 (GlobalMa (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "preds (Dense)                (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 6,518,073\n",
            "Trainable params: 674,373\n",
            "Non-trainable params: 5,843,700\n",
            "_________________________________________________________________\n",
            "Epoch 1/32\n",
            "122/122 [==============================] - 62s 231ms/step - loss: 1.0817 - accuracy: 0.5657 - val_loss: 0.9603 - val_accuracy: 0.5947\n",
            "Epoch 2/32\n",
            "122/122 [==============================] - 27s 222ms/step - loss: 0.9381 - accuracy: 0.6139 - val_loss: 0.9565 - val_accuracy: 0.6141\n",
            "Epoch 3/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.9084 - accuracy: 0.6251 - val_loss: 0.9127 - val_accuracy: 0.6212\n",
            "Epoch 4/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.8870 - accuracy: 0.6337 - val_loss: 0.8980 - val_accuracy: 0.6287\n",
            "Epoch 5/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.8654 - accuracy: 0.6439 - val_loss: 0.8905 - val_accuracy: 0.6324\n",
            "Epoch 6/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.8444 - accuracy: 0.6523 - val_loss: 0.8870 - val_accuracy: 0.6314\n",
            "Epoch 7/32\n",
            "122/122 [==============================] - 27s 225ms/step - loss: 0.8261 - accuracy: 0.6592 - val_loss: 0.8751 - val_accuracy: 0.6357\n",
            "Epoch 8/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.8109 - accuracy: 0.6649 - val_loss: 0.8820 - val_accuracy: 0.6358\n",
            "Epoch 9/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.7950 - accuracy: 0.6734 - val_loss: 0.8773 - val_accuracy: 0.6339\n",
            "Epoch 10/32\n",
            "122/122 [==============================] - 27s 225ms/step - loss: 0.7827 - accuracy: 0.6770 - val_loss: 0.8682 - val_accuracy: 0.6411\n",
            "Epoch 11/32\n",
            "122/122 [==============================] - 27s 225ms/step - loss: 0.7671 - accuracy: 0.6820 - val_loss: 0.8807 - val_accuracy: 0.6344\n",
            "Epoch 12/32\n",
            "122/122 [==============================] - 27s 225ms/step - loss: 0.7576 - accuracy: 0.6871 - val_loss: 0.8699 - val_accuracy: 0.6387\n",
            "Epoch 13/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.7456 - accuracy: 0.6934 - val_loss: 0.8814 - val_accuracy: 0.6394\n",
            "Epoch 14/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.7390 - accuracy: 0.6940 - val_loss: 0.8701 - val_accuracy: 0.6423\n",
            "Epoch 15/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.7290 - accuracy: 0.6992 - val_loss: 0.8913 - val_accuracy: 0.6363\n",
            "Epoch 16/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.7220 - accuracy: 0.7010 - val_loss: 0.8643 - val_accuracy: 0.6425\n",
            "Epoch 17/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.7135 - accuracy: 0.7049 - val_loss: 0.8745 - val_accuracy: 0.6407\n",
            "Epoch 18/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.7069 - accuracy: 0.7079 - val_loss: 0.8630 - val_accuracy: 0.6421\n",
            "Epoch 19/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6997 - accuracy: 0.7119 - val_loss: 0.8764 - val_accuracy: 0.6365\n",
            "Epoch 20/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6939 - accuracy: 0.7131 - val_loss: 0.8658 - val_accuracy: 0.6435\n",
            "Epoch 21/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6889 - accuracy: 0.7148 - val_loss: 0.8774 - val_accuracy: 0.6378\n",
            "Epoch 22/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6826 - accuracy: 0.7167 - val_loss: 0.8775 - val_accuracy: 0.6433\n",
            "Epoch 23/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6773 - accuracy: 0.7182 - val_loss: 0.8721 - val_accuracy: 0.6400\n",
            "Epoch 24/32\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.6714 - accuracy: 0.7213 - val_loss: 0.8680 - val_accuracy: 0.6445\n",
            "Epoch 25/32\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.6705 - accuracy: 0.7217 - val_loss: 0.8730 - val_accuracy: 0.6426\n",
            "Epoch 26/32\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.6640 - accuracy: 0.7251 - val_loss: 0.8781 - val_accuracy: 0.6410\n",
            "Epoch 27/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6580 - accuracy: 0.7255 - val_loss: 0.8957 - val_accuracy: 0.6365\n",
            "Epoch 28/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6533 - accuracy: 0.7290 - val_loss: 0.8729 - val_accuracy: 0.6423\n",
            "Epoch 29/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6495 - accuracy: 0.7297 - val_loss: 0.8846 - val_accuracy: 0.6417\n",
            "Epoch 30/32\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.6472 - accuracy: 0.7311 - val_loss: 0.8864 - val_accuracy: 0.6367\n",
            "Epoch 31/32\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.6442 - accuracy: 0.7314 - val_loss: 0.8790 - val_accuracy: 0.6394\n",
            "Epoch 32/32\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.6367 - accuracy: 0.7330 - val_loss: 0.8975 - val_accuracy: 0.6352\n",
            "min loss (0): 0.6367\n",
            "min val_loss (0): 0.863\n",
            "max accuracy (0): 0.733\n",
            "max val_accuracy (0): 0.6445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCc8Ju7tqOjt"
      },
      "source": [
        "## Optimize with lr_scheduler and early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2w5k64kqU_5"
      },
      "source": [
        "lr_scheduler = None\n",
        "early_stopping = None\n",
        "# DEFINE YOUR lr_scheduler AND early_stopping callbacks\n",
        "# START CODE HERE\n",
        "def scheduler(epoch, lr):\n",
        "    # EXPERIMENT YOURSELF\n",
        "    decay_rate = 0.1\n",
        "    decay_step = 90\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1,\n",
        "                               mode='min', baseline=None, restore_best_weights=True)\n",
        "# END CODE HERE"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NEb3YShqnpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d7db41-84b7-46e6-f891-68f8474bec7b"
      },
      "source": [
        "classifiers = []\n",
        "model_index = list(range(classifier_num))  # for ensemble, kfold split - do it yourself\n",
        "\n",
        "for i in model_index:\n",
        "    classifier = one_input_classifier(i, max_length, max_features, class_num, embedding_dim, embedding_matrix)\n",
        "\n",
        "    if i == 0:\n",
        "        classifier.summary()\n",
        "\n",
        "    hist = classifier.fit(np_x_train, np_y_train, validation_split=validation_split, shuffle=True,\n",
        "                          callbacks=[early_stopping, lr_scheduler], epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "    classifier.trainable = False\n",
        "    classifiers.append(classifier)\n",
        "\n",
        "    print('min loss ({}): {:.4}'.format(i, min(hist.history['loss'])))\n",
        "    print('min val_loss ({}): {:.4}'.format(i, min(hist.history['val_loss'])))\n",
        "    print('max accuracy ({}): {:.4}'.format(i, max(hist.history['accuracy'])))\n",
        "    print('max val_accuracy ({}): {:.4}'.format(i, max(hist.history['val_accuracy'])))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_0\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 60)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 60, 300)           5843700   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 60, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 60, 256)           440320    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 56, 128)           163968    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 54, 128)           49280     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 54, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 54, 128)           0         \n",
            "_________________________________________________________________\n",
            "global_maxpool1d_1 (GlobalMa (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "preds (Dense)                (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 6,518,073\n",
            "Trainable params: 674,373\n",
            "Non-trainable params: 5,843,700\n",
            "_________________________________________________________________\n",
            "Epoch 1/32\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 31s 228ms/step - loss: 1.0686 - accuracy: 0.5716 - val_loss: 0.9573 - val_accuracy: 0.6113\n",
            "Epoch 2/32\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 225ms/step - loss: 0.9314 - accuracy: 0.6167 - val_loss: 0.9423 - val_accuracy: 0.6190\n",
            "Epoch 3/32\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.8999 - accuracy: 0.6300 - val_loss: 0.9145 - val_accuracy: 0.6235\n",
            "Epoch 4/32\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.8771 - accuracy: 0.6389 - val_loss: 0.9085 - val_accuracy: 0.6300\n",
            "Epoch 5/32\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.8566 - accuracy: 0.6464 - val_loss: 0.9006 - val_accuracy: 0.6287\n",
            "Epoch 6/32\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 224ms/step - loss: 0.8369 - accuracy: 0.6537 - val_loss: 0.8793 - val_accuracy: 0.6361\n",
            "Epoch 7/32\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.8151 - accuracy: 0.6627 - val_loss: 0.8743 - val_accuracy: 0.6360\n",
            "Epoch 8/32\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.8034 - accuracy: 0.6689 - val_loss: 0.8759 - val_accuracy: 0.6391\n",
            "Epoch 9/32\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "122/122 [==============================] - 27s 223ms/step - loss: 0.7836 - accuracy: 0.6760 - val_loss: 0.8808 - val_accuracy: 0.6362\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "min loss (0): 0.7836\n",
            "min val_loss (0): 0.8743\n",
            "max accuracy (0): 0.676\n",
            "max val_accuracy (0): 0.6391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsbrIpXmnquU"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mpvutskqh65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d14be41-47b0-4103-9be0-0d91cfaac98c"
      },
      "source": [
        "y_pred_list = []\n",
        "\n",
        "for i in range(classifier_num):\n",
        "    y_pred = classifiers[i].predict(np_x_test, batch_size=1024, verbose=1)\n",
        "    y_pred_list.append(y_pred)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 [==============================] - 5s 72ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcLO0qUNbM6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "182fb070-1aee-4292-b416-6df71b05fe54"
      },
      "source": [
        "test_num = np_x_test.shape[0]\n",
        "y_pred_class = np.ndarray(shape=(test_num,), dtype=np.int32)\n",
        "\n",
        "for i in range(test_num):\n",
        "    votes = []\n",
        "\n",
        "    for j in range(classifier_num):\n",
        "        vote = y_pred_list[j][i].argmax(axis=0).astype(int)\n",
        "        votes.append(vote)\n",
        "\n",
        "    vote_final = max(set(votes), key=votes.count)\n",
        "    y_pred_class[i] = vote_final\n",
        "\n",
        "mapping = {phrase: sentiment for _, _, phrase, sentiment in train.values}\n",
        "\n",
        "# Overlapping\n",
        "for i, phrase in enumerate(test.Phrase.values):\n",
        "    if phrase in mapping:\n",
        "        y_pred_class[i] = mapping[phrase]\n",
        "\n",
        "test['Sentiment'] = y_pred_class\n",
        "test.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0    156061  ...          3\n",
              "1    156062  ...          3\n",
              "2    156063  ...          2\n",
              "3    156064  ...          3\n",
              "4    156065  ...          3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}